time()
data_class_0 = Array([[5.1, 3.5, 1.4, 0.2, 1., 0., 0.],
                      [4.9, 3., 1.4, 0.2, 1., 0., 0.],
                      [4.7, 3.2, 1.3, 0.2, 1., 0., 0.],
                      [4.6, 3.1, 1.5, 0.2, 1., 0., 0.],
                      [5., 3.6, 1.4, 0.2, 1., 0., 0.],
                      [5.4, 3.9, 1.7, 0.4, 1., 0., 0.],
                      [4.6, 3.4, 1.4, 0.3, 1., 0., 0.],
                      [5., 3.4, 1.5, 0.2, 1., 0., 0.],
                      [4.4, 2.9, 1.4, 0.2, 1., 0., 0.],
                      [4.9, 3.1, 1.5, 0.1, 1., 0., 0.],
                      [5.4, 3.7, 1.5, 0.2, 1., 0., 0.],
                      [4.8, 3.4, 1.6, 0.2, 1., 0., 0.],
                      [4.8, 3., 1.4, 0.1, 1., 0., 0.],
                      [4.3, 3., 1.1, 0.1, 1., 0., 0.],
                      [5.8, 4., 1.2, 0.2, 1., 0., 0.],
                      [5.7, 4.4, 1.5, 0.4, 1., 0., 0.],
                      [5.4, 3.9, 1.3, 0.4, 1., 0., 0.],
                      [5.1, 3.5, 1.4, 0.3, 1., 0., 0.],
                      [5.7, 3.8, 1.7, 0.3, 1., 0., 0.],
                      [5.1, 3.8, 1.5, 0.3, 1., 0., 0.],
                      [5.4, 3.4, 1.7, 0.2, 1., 0., 0.],
                      [5.1, 3.7, 1.5, 0.4, 1., 0., 0.],
                      [4.6, 3.6, 1., 0.2, 1., 0., 0.],
                      [5.1, 3.3, 1.7, 0.5, 1., 0., 0.],
                      [4.8, 3.4, 1.9, 0.2, 1., 0., 0.],
                      [5., 3., 1.6, 0.2, 1., 0., 0.],
                      [5., 3.4, 1.6, 0.4, 1., 0., 0.],
                      [5.2, 3.5, 1.5, 0.2, 1., 0., 0.],
                      [5.2, 3.4, 1.4, 0.2, 1., 0., 0.],
                      [4.7, 3.2, 1.6, 0.2, 1., 0., 0.],
                      [4.8, 3.1, 1.6, 0.2, 1., 0., 0.],
                      [5.4, 3.4, 1.5, 0.4, 1., 0., 0.],
                      [5.2, 4.1, 1.5, 0.1, 1., 0., 0.],
                      [5.5, 4.2, 1.4, 0.2, 1., 0., 0.],
                      [4.9, 3.1, 1.5, 0.1, 1., 0., 0.],
                      [5., 3.2, 1.2, 0.2, 1., 0., 0.],
                      [5.5, 3.5, 1.3, 0.2, 1., 0., 0.],
                      [4.9, 3.1, 1.5, 0.1, 1., 0., 0.],
                      [4.4, 3., 1.3, 0.2, 1., 0., 0.],
                      [5.1, 3.4, 1.5, 0.2, 1., 0., 0.],
                      [5., 3.5, 1.3, 0.3, 1., 0., 0.],
                      [4.5, 2.3, 1.3, 0.3, 1., 0., 0.],
                      [4.4, 3.2, 1.3, 0.2, 1., 0., 0.],
                      [5., 3.5, 1.6, 0.6, 1., 0., 0.],
                      [5.1, 3.8, 1.9, 0.4, 1., 0., 0.],
                      [4.8, 3., 1.4, 0.3, 1., 0., 0.],
                      [5.1, 3.8, 1.6, 0.2, 1., 0., 0.],
                      [4.6, 3.2, 1.4, 0.2, 1., 0., 0.],
                      [5.3, 3.7, 1.5, 0.2, 1., 0., 0.],
                      [5., 3.3, 1.4, 0.2, 1., 0., 0.]])
data_class_1 = Array([[7., 3.2, 4.7, 1.4, 0., 1., 0.],
                      [6.4, 3.2, 4.5, 1.5, 0., 1., 0.],
                      [6.9, 3.1, 4.9, 1.5, 0., 1., 0.],
                      [5.5, 2.3, 4., 1.3, 0., 1., 0.],
                      [6.5, 2.8, 4.6, 1.5, 0., 1., 0.],
                      [5.7, 2.8, 4.5, 1.3, 0., 1., 0.],
                      [6.3, 3.3, 4.7, 1.6, 0., 1., 0.],
                      [4.9, 2.4, 3.3, 1., 0., 1., 0.],
                      [6.6, 2.9, 4.6, 1.3, 0., 1., 0.],
                      [5.2, 2.7, 3.9, 1.4, 0., 1., 0.],
                      [5., 2., 3.5, 1., 0., 1., 0.],
                      [5.9, 3., 4.2, 1.5, 0., 1., 0.],
                      [6., 2.2, 4., 1., 0., 1., 0.],
                      [6.1, 2.9, 4.7, 1.4, 0., 1., 0.],
                      [5.6, 2.9, 3.6, 1.3, 0., 1., 0.],
                      [6.7, 3.1, 4.4, 1.4, 0., 1., 0.],
                      [5.6, 3., 4.5, 1.5, 0., 1., 0.],
                      [5.8, 2.7, 4.1, 1., 0., 1., 0.],
                      [6.2, 2.2, 4.5, 1.5, 0., 1., 0.],
                      [5.6, 2.5, 3.9, 1.1, 0., 1., 0.],
                      [5.9, 3.2, 4.8, 1.8, 0., 1., 0.],
                      [6.1, 2.8, 4., 1.3, 0., 1., 0.],
                      [6.3, 2.5, 4.9, 1.5, 0., 1., 0.],
                      [6.1, 2.8, 4.7, 1.2, 0., 1., 0.],
                      [6.4, 2.9, 4.3, 1.3, 0., 1., 0.],
                      [6.6, 3., 4.4, 1.4, 0., 1., 0.],
                      [6.8, 2.8, 4.8, 1.4, 0., 1., 0.],
                      [6.7, 3., 5., 1.7, 0., 1., 0.],
                      [6., 2.9, 4.5, 1.5, 0., 1., 0.],
                      [5.7, 2.6, 3.5, 1., 0., 1., 0.],
                      [5.5, 2.4, 3.8, 1.1, 0., 1., 0.],
                      [5.5, 2.4, 3.7, 1., 0., 1., 0.],
                      [5.8, 2.7, 3.9, 1.2, 0., 1., 0.],
                      [6., 2.7, 5.1, 1.6, 0., 1., 0.],
                      [5.4, 3., 4.5, 1.5, 0., 1., 0.],
                      [6., 3.4, 4.5, 1.6, 0., 1., 0.],
                      [6.7, 3.1, 4.7, 1.5, 0., 1., 0.],
                      [6.3, 2.3, 4.4, 1.3, 0., 1., 0.],
                      [5.6, 3., 4.1, 1.3, 0., 1., 0.],
                      [5.5, 2.5, 4., 1.3, 0., 1., 0.],
                      [5.5, 2.6, 4.4, 1.2, 0., 1., 0.],
                      [6.1, 3., 4.6, 1.4, 0., 1., 0.],
                      [5.8, 2.6, 4., 1.2, 0., 1., 0.],
                      [5., 2.3, 3.3, 1., 0., 1., 0.],
                      [5.6, 2.7, 4.2, 1.3, 0., 1., 0.],
                      [5.7, 3., 4.2, 1.2, 0., 1., 0.],
                      [5.7, 2.9, 4.2, 1.3, 0., 1., 0.],
                      [6.2, 2.9, 4.3, 1.3, 0., 1., 0.],
                      [5.1, 2.5, 3., 1.1, 0., 1., 0.],
                      [5.7, 2.8, 4.1, 1.3, 0., 1., 0.]])
data_class_2 = Array([[6.3, 3.3, 6., 2.5, 0., 0., 1.],
                      [5.8, 2.7, 5.1, 1.9, 0., 0., 1.],
                      [7.1, 3., 5.9, 2.1, 0., 0., 1.],
                      [6.3, 2.9, 5.6, 1.8, 0., 0., 1.],
                      [6.5, 3., 5.8, 2.2, 0., 0., 1.],
                      [7.6, 3., 6.6, 2.1, 0., 0., 1.],
                      [4.9, 2.5, 4.5, 1.7, 0., 0., 1.],
                      [7.3, 2.9, 6.3, 1.8, 0., 0., 1.],
                      [6.7, 2.5, 5.8, 1.8, 0., 0., 1.],
                      [7.2, 3.6, 6.1, 2.5, 0., 0., 1.],
                      [6.5, 3.2, 5.1, 2., 0., 0., 1.],
                      [6.4, 2.7, 5.3, 1.9, 0., 0., 1.],
                      [6.8, 3., 5.5, 2.1, 0., 0., 1.],
                      [5.7, 2.5, 5., 2., 0., 0., 1.],
                      [5.8, 2.8, 5.1, 2.4, 0., 0., 1.],
                      [6.4, 3.2, 5.3, 2.3, 0., 0., 1.],
                      [6.5, 3., 5.5, 1.8, 0., 0., 1.],
                      [7.7, 3.8, 6.7, 2.2, 0., 0., 1.],
                      [7.7, 2.6, 6.9, 2.3, 0., 0., 1.],
                      [6., 2.2, 5., 1.5, 0., 0., 1.],
                      [6.9, 3.2, 5.7, 2.3, 0., 0., 1.],
                      [5.6, 2.8, 4.9, 2., 0., 0., 1.],
                      [7.7, 2.8, 6.7, 2., 0., 0., 1.],
                      [6.3, 2.7, 4.9, 1.8, 0., 0., 1.],
                      [6.7, 3.3, 5.7, 2.1, 0., 0., 1.],
                      [7.2, 3.2, 6., 1.8, 0., 0., 1.],
                      [6.2, 2.8, 4.8, 1.8, 0., 0., 1.],
                      [6.1, 3., 4.9, 1.8, 0., 0., 1.],
                      [6.4, 2.8, 5.6, 2.1, 0., 0., 1.],
                      [7.2, 3., 5.8, 1.6, 0., 0., 1.],
                      [7.4, 2.8, 6.1, 1.9, 0., 0., 1.],
                      [7.9, 3.8, 6.4, 2., 0., 0., 1.],
                      [6.4, 2.8, 5.6, 2.2, 0., 0., 1.],
                      [6.3, 2.8, 5.1, 1.5, 0., 0., 1.],
                      [6.1, 2.6, 5.6, 1.4, 0., 0., 1.],
                      [7.7, 3., 6.1, 2.3, 0., 0., 1.],
                      [6.3, 3.4, 5.6, 2.4, 0., 0., 1.],
                      [6.4, 3.1, 5.5, 1.8, 0., 0., 1.],
                      [6., 3., 4.8, 1.8, 0., 0., 1.],
                      [6.9, 3.1, 5.4, 2.1, 0., 0., 1.],
                      [6.7, 3.1, 5.6, 2.4, 0., 0., 1.],
                      [6.9, 3.1, 5.1, 2.3, 0., 0., 1.],
                      [5.8, 2.7, 5.1, 1.9, 0., 0., 1.],
                      [6.8, 3.2, 5.9, 2.3, 0., 0., 1.],
                      [6.7, 3.3, 5.7, 2.5, 0., 0., 1.],
                      [6.7, 3., 5.2, 2.3, 0., 0., 1.],
                      [6.3, 2.5, 5., 1.9, 0., 0., 1.],
                      [6.5, 3., 5.2, 2., 0., 0., 1.],
                      [6.2, 3.4, 5.4, 2.3, 0., 0., 1.],
                      [5.9, 3., 5.1, 1.8, 0., 0., 1.]]);
train_ratio = 0.8
train_set = Concatenate([Array(data_class_0[:int(train_ratio * len(data_class_0))]),
                         Array(data_class_1[:int(train_ratio * len(data_class_1))]),
                         Array(data_class_2[:int(train_ratio * len(data_class_2))])])
test_set = Concatenate([Array(data_class_0[int(train_ratio * len(data_class_0)):]),
                        Array(data_class_1[int(train_ratio * len(data_class_1)):]),
                        Array(data_class_2[int(train_ratio * len(data_class_2)):])])

Shuffle(train_set)
Shuffle(test_set)


class Graph:
    def __init__(self):
        self.nodes = []

    def add_node(self, node):
        self.nodes.append(node)

    def clear_jacobi(self):
        for node in self.nodes:
            node.clear_jacobi()

    def reset_value(self):
        for node in self.nodes:
            node.reset_value()


graph = Graph()


class Node:
    def __init__(self, parents):
        self.graph = graph
        self.parents = parents
        self.children = []
        self.value = None
        self.jacobi = None
        self.trainable = False

        for parent in self.parents:
            parent.children.append(self)

        self.graph.add_node(self)

    def get_parents(self):
        return self.parents

    def get_children(self):
        return self.children

    def forward(self):
        for node in self.parents:
            if node.value is None:
                node.forward()
        self.compute()

    def compute(self):
        pass

    def backward(self, result):
        if self.jacobi is None:
            if self is result:
                self.jacobi = Eye(self.get_dimension())
            else:
                self.jacobi = Zeros([result.get_dimension(), self.get_dimension()])
                for child in self.get_children():
                    if child.value is not None:
                        left = child.backward(result)
                        right = child.get_jacobi(self)
                        self.jacobi += left @ right
        return self.jacobi

    def clear_jacobi(self):
        self.jacobi = None

    def reset_value(self):
        self.value = None
        for child in self.children:
            child.reset_value()

    def get_shape(self):
        return self.value.shape

    def get_dimension(self):
        return self.value.shape[0] * self.value.shape[1]


class Variable(Node):
    def __init__(self, dim, init, trainable):
        self.graph = graph
        self.parents = []
        self.children = []
        self.value = None
        self.jacobi = None
        self.graph.add_node(self)
        self.dim = dim
        self.trainable = trainable
        if init:
            self.value = Normal(0.0, 0.001, self.dim)

    def set_value(self, value):
        self.reset_value()
        self.value = value


class Operator(Node):
    pass


class Add(Operator):
    def compute(self):
        self.value = Zeros(self.parents[0].get_shape())
        for parent in self.parents:
            self.value += parent.value

    def get_jacobi(self, parent):
        return Eye(self.get_dimension())


class MatrixMultiply(Operator):
    def compute(self):
        self.value = self.parents[0].value @ self.parents[1].value

    def get_jacobi(self, parent):
        parent0 = self.parents[0]
        parent1 = self.parents[1]
        lhs_shape = parent0.get_shape()
        m = lhs_shape[0]
        n = lhs_shape[1]
        k = parent1.get_shape()[1]
        if parent is parent0:
            # C 对 A 的雅可比矩阵
            t = parent1.value.T
            jacobi = Zeros([m * k, m * n])
            for i in range(m):
                jacobi[i * k:(i + 1) * k, i * n:(i + 1) * n] = t
            return jacobi
        if parent is parent1:
            jacobi = Zeros([m * k, n * k])
            for i in range(m):
                for j in range(n):
                    jacobi[i * k:(i + 1) * k, j * k:(j + 1) * k] = Eye(k) * parent0.value[i, j]
            return jacobi


class ScalarMultiply(Operator):
    def compute(self):
        self.value = self.parents[0].value * self.parents[1].value

    def get_jacobi(self, parent):
        parent0 = self.parents[0]
        parent1 = self.parents[1]
        if parent is parent0:
            return Diag(parent1.value.ravel())
        if parent is parent1:
            return Eye(parent1.get_dimension()) * self.parents[0].value[0, 0]


class Multiply(Operator):
    def compute(self):
        self.value = self.parents[0].value * self.parents[1].value

    def get_jacobi(self, parent):
        parent0 = self.parents[0]
        parent1 = self.parents[1]
        if parent is parent0:
            return Diag(parent1.value.ravel())
        if parent is parent1:
            return Diag(parent0.value.ravel())


class Step(Operator):
    def compute(self):
        parent0 = self.parents[0]
        shape = parent0.get_shape()
        self.value = Zeros(shape)
        for i in range(shape[0]):
            for j in range(shape[1]):
                if parent0.value[i, j] >= 0.0:
                    self.value[i, j] = 1.0

    def get_jacobi(self, parent):
        return Zeros(self.parents[0].get_shape())


class SoftMax(Operator):
    def compute(self):
        self.value = Softmax(self.parents[0].value)


class Optimizer(object):
    def __init__(self, graph, target, learning_rate):
        self.graph = graph
        self.target = target
        self.learning_rate = learning_rate
        self.gradient = dict()
        self.steps = 0

    def step(self):
        self.graph.clear_jacobi()
        self.target.forward()
        for node in self.graph.nodes:
            if node.trainable:
                node.backward(self.target)
                gradient = node.jacobi.T.reshape(node.get_shape())
                if node not in self.gradient:
                    self.gradient[node] = gradient
                else:
                    self.gradient[node] += gradient
        self.steps += 1

    def get_gradient(self, node):
        return self.gradient[node] / self.steps

    def update_impl(self):
        pass

    def update(self):
        self.update_impl()
        self.gradient.clear()
        self.steps = 0


class GradientDescent(Optimizer):
    def __init__(self, graph, target, learning_rate):
        Optimizer.__init__(self, graph, target, learning_rate)
        self.learning_rate = learning_rate

    def update_impl(self):
        for node in self.graph.nodes:
            if node.trainable:
                gradient = self.get_gradient(node)
                node.set_value(node.value - gradient * self.learning_rate)


class Momentum(Optimizer):
    def __init__(self, graph, target, learning_rate, momentum):
        Optimizer.__init__(self, graph, target, learning_rate)
        self.learning_rate = learning_rate
        self.momentum = momentum
        self.v = dict()

    def update_impl(self):
        for node in self.graph.nodes:
            if node.trainable:
                gradient = self.get_gradient(node)
                if node not in self.v:
                    self.v[node] = gradient
                else:
                    self.v[node] = self.v[node] * self.momentum - gradient * self.learning_rate
                node.set_value(node.value + self.v[node])


class LossFunction(Node):
    pass


class PerceptionLoss(LossFunction):
    def compute(self):
        parent0 = self.parents[0]
        shape = parent0.get_shape()
        row = shape[0]
        col = shape[1]
        self.value = Zeros(shape)
        for i in range(row):
            for j in range(col):
                if parent0.value[i, j] >= 0.0:
                    self.value[i, j] = 0.0
                else:
                    self.value[i, j] = -parent0.value[i, j]

    def get_jacobi(self, parent):
        parent0 = self.parents[0]
        shape = parent0.get_shape()
        row = shape[0]
        col = shape[1]
        diag = Zeros(shape)
        for i in range(row):
            for j in range(col):
                if parent0.value[i, j] < 0.0:
                    diag[i, j] = -1.0
        return Diag(diag.ravel())


class LogLoss(LossFunction):
    def compute(self):
        self.value = LogisticLoss(self.parents[0].value)

    def get_jacobi(self, parent):
        diag = LogisticLossDerivative(parent.value)
        return Diag(diag.ravel())


class CrossEntropyWithSoftMax(LossFunction):
    def compute(self):
        prob = Softmax(self.parents[0].value)
        value = -Sum(self.parents[1].value * Log(prob))
        self.value = Array(value).reshape([1, 1])

    def get_jacobi(self, parent):
        prob = Softmax(self.parents[0].value)
        if parent is self.parents[0]:
            return (prob - self.parents[1].value).T
        else:
            return (-Log(prob)).T


x = Variable([4, 1], False, False)
label = Variable([3, 1], False, False)
W = Variable([3, 4], True, True)
b = Variable([3, 1], True, True)
linear = Add([MatrixMultiply([W, x]), b])
predict = SoftMax([linear])
loss = CrossEntropyWithSoftMax([linear, label])
learning_rate = 0.01
optimizer = Momentum(graph, loss, learning_rate, 0.9)
batch_size = 16


def predict_and_evaluate(data, predict, input):
    size = len(data)
    pred = []
    for i in range(size):
        features = data[i, :-3].T.reshape([4, 1])
        input.set_value(features)
        predict.forward()
        pred.append(ArgMax(predict.value.T))
    total = 0
    expected = data[:, -3:]
    for i in range(len(pred)):
        if expected[i, pred[i]] == 1.0:
            total += 1
    accuracy = total / size
    return accuracy


for epoch in range(50):
    batch_counter = 0
    for i in range(len(train_set)):
        features = train_set[i, :-3].T.reshape([4, 1])
        l = Array(train_set[i, -3:]).T.reshape([3, 1])
        x.set_value(features)
        label.set_value(l)
        optimizer.step()
        batch_counter += 1
        if batch_counter == batch_size:
            optimizer.update()
            batch_counter = 0
    accuracy = predict_and_evaluate(train_set, predict, x)
    print("epoch: ", epoch + 1, " accuracy: ", accuracy)
accuracy = predict_and_evaluate(test_set, predict, x)
print("test accuracy: ", accuracy)

time()
